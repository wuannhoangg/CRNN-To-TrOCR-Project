# ƒê·ªì √°n: C·∫£i ti·∫øn OCR ch·ªØ vi·∫øt tay ti·∫øng Vi·ªát v·ªõi TrOCR v√† H·∫≠u x·ª≠ l√Ω Ng√¥n ng·ªØ
[cite_start]D·ª± √°n n√†y l√† ƒë·ªì √°n m√¥n h·ªçc, nh·∫±m m·ª•c ti√™u c·∫£i ti·∫øn h·ªá th·ªëng nh·∫≠n d·∫°ng ch·ªØ vi·∫øt tay ti·∫øng Vi·ªát b·∫±ng c√°ch[cite: 3]:

1.  [cite_start]S·ª≠ d·ª•ng m√¥ h√¨nh Transformer (TrOCR) l√†m m√¥ h√¨nh ch√≠nh[cite: 3].
2.  [cite_start]T√≠ch h·ª£p m√¥ h√¨nh ng√¥n ng·ªØ (KenLM) ƒë·ªÉ h·∫≠u x·ª≠ l√Ω, tƒÉng ƒë·ªô ch√≠nh x√°c[cite: 3, 9].
3.  [cite_start]X√¢y d·ª±ng pipeline End-to-End (E2E) v·ªõi Text Detection (DBNet)[cite: 3, 9].

D·ª± √°n ƒë∆∞·ª£c x√¢y d·ª±ng v√† c·∫£i ti·∫øn d·ª±a tr√™n m√£ ngu·ªìn CRNN baseline c·ªßa **TomHuynhSG/Vietnamese-Handwriting-Recognition-OCR**.

-----

## üöÄ Demo Tr·ª±c Ti·∫øp (Web Application)

[cite_start]B·∫°n c√≥ th·ªÉ tr·∫£i nghi·ªám pipeline ho√†n ch·ªânh (Detection + Recognition + Language Model) t·∫°i web demo do nh√≥m tri·ªÉn khai[cite: 6, 9].

**Link Demo:** [https://huggingface.co/spaces/wuann/TrOCR_Demo](https://huggingface.co/spaces/wuann/TrOCR_Demo)
-----

## üìä K·∫øt qu·∫£ So s√°nh

[cite_start]K·∫øt qu·∫£ ƒë√°nh gi√° tr√™n t·∫≠p test ƒë·ªôc l·∫≠p cho th·∫•y m√¥ h√¨nh Transformer (TrOCR) k·∫øt h·ª£p v·ªõi H·∫≠u x·ª≠ l√Ω Ng√¥n ng·ªØ (LM) cho k·∫øt qu·∫£ v∆∞·ª£t tr·ªôi so v·ªõi baseline CRNN[cite: 6, 9].

| M√¥ h√¨nh | CER (L·ªói K√Ω t·ª±) ‚¨áÔ∏è | WER (L·ªói T·ª´) ‚¨áÔ∏è |
| :--- | :---: | :---: |
| CRNN (Baseline) | *9.56%* | *27.52%* |
| **TrOCR (C·∫£i ti·∫øn)** | *9.01%* | *19.43%* |


-----

## üìÅ C·∫•u tr√∫c th∆∞ m·ª•c

```
vn-handwriting-ocr/
‚îú‚îÄ‚îÄ configs/                # Ch·ª©a file .yml config cho training
‚îú‚îÄ‚îÄ data/                   # N∆°i ch·ª©a d·ªØ li·ªáu (B·ªä GIT B·ªé QUA)
‚îÇ   ‚îú‚îÄ‚îÄ alphabet_vi_full.txt
‚îÇ   ‚îî‚îÄ‚îÄ README.md           # H∆∞·ªõng d·∫´n t·∫£i data
‚îú‚îÄ‚îÄ models/                 # N∆°i ch·ª©a checkpoint (B·ªä GIT B·ªé QUA)
‚îÇ   ‚îî‚îÄ‚îÄ README.md           # H∆∞·ªõng d·∫´n t·∫£i model
‚îú‚îÄ‚îÄ src/                    # TO√ÄN B·ªò CODE HU·∫§N LUY·ªÜN & ƒê√ÅNH GI√Å
‚îÇ   ‚îú‚îÄ‚îÄ crnn/               # Module cho model CRNN baseline
‚îÇ   ‚îú‚îÄ‚îÄ transformer/        # Module cho model TrOCR c·∫£i ti·∫øn
‚îÇ   ‚îî‚îÄ‚îÄ utils/              # C√°c h√†m d√πng chung (metrics, dataset,...)
‚îÇ
‚îú‚îÄ‚îÄ web_demo/               # CODE DEMO (FastAPI + Docker)
‚îÇ   ‚îú‚îÄ‚îÄ app/                # Code FastAPI (main.py, pipeline.py)
‚îÇ   ‚îú‚îÄ‚îÄ models/             # Models d√πng cho demo (ƒë∆∞·ª£c LFS theo d√µi)
‚îÇ   ‚îú‚îÄ‚îÄ Dockerfile
‚îÇ   ‚îî‚îÄ‚îÄ requirements.txt
‚îÇ
‚îú‚îÄ‚îÄ .gitignore              # File b·ªè qua c·ªßa Git
‚îú‚îÄ‚îÄ README.md               # File n√†y
‚îî‚îÄ‚îÄ requirements.txt        # Th∆∞ vi·ªán cho hu·∫•n luy·ªán (src/)
```

-----

## ‚öôÔ∏è C√†i ƒë·∫∑t & H∆∞·ªõng d·∫´n s·ª≠ d·ª•ng

### A. Chu·∫©n b·ªã (B·∫Øt bu·ªôc)

1.  **Clone d·ª± √°n:**

    ```bash
    git clone https://github.com/ten-ban/vn-handwriting-ocr
    cd vn-handwriting-ocr
    ```

2.  **C√†i ƒë·∫∑t Git LFS (ƒë·ªÉ t·∫£i model cho `web_demo`):**

    ```bash
    git lfs install
    git lfs pull
    ```

3.  **Thi·∫øt l·∫≠p m√¥i tr∆∞·ªùng (Windows):**

    * (T√πy ch·ªçn) S·ª≠a l·ªói hi·ªÉn th·ªã UTF-8 tr√™n CMD:
    ```cmd
    chcp 65001 >NUL
    set PYTHONIOENCODING=utf-8
    ```
    * K√≠ch ho·∫°t m√¥i tr∆∞·ªùng ·∫£o (v√≠ d·ª• c·ªßa b·∫°n):
    ```cmd
    .\.venv-py311\Scripts\activate
    ```
    * C√†i ƒë·∫∑t th∆∞ vi·ªán cho Hu·∫•n luy·ªán & ƒê√°nh gi√°:
    ```bash
    pip install -r requirements.txt
    ```
    * C√†i ƒë·∫∑t PyTorch: Truy c·∫≠p v√†o trang web https://pytorch.org/get-started/locally/ v√† c√†i PyTorch theo √Ω b·∫°n
    ```bash
    pip3 install torch torchvision --index-url https://download.pytorch.org/whl/cu126 #N·∫øu b·∫°n d√πng GPU
    pip3 install torch torchvision #N·∫øu b·∫°n d√πng CPU
    ```

4.  **T·∫£i D·ªØ li·ªáu (Data):**

      * **ƒê·ªåC K·ª∏:** `data/README.md`.
      * B·∫°n c·∫ßn t·∫£i v√† gi·∫£i n√©n d·ªØ li·ªáu v√†o th∆∞ m·ª•c `data/` tr∆∞·ªõc khi train.

5.  **T·∫£i Model (Checkpoints):**

      * **ƒê·ªåC K·ª∏:** `models/README.md`.
      * B·∫°n c·∫ßn t·∫£i c√°c model ƒë√£ hu·∫•n luy·ªán (v√≠ d·ª•: `best_transformer.pt`, `best_crnn.pt`, `3-gram-lm.binary`) v√† ƒë·∫∑t v√†o th∆∞ m·ª•c `models/`.

### B. Hu·∫•n luy·ªán (Training)

(C√°c l·ªánh ƒë∆∞·ª£c ch·∫°y t·ª´ th∆∞ m·ª•c g·ªëc `vn-handwriting-ocr/`)

#### 1\. Hu·∫•n luy·ªán Transformer (TrOCR)

Ch·∫°y training b·∫±ng c√°ch g·ªçi module `src.transformer.train`:

```cmd
python -m src.transformer.train --config "configs/transformer_config.yml" --resume_from "models/best_transformer.pt"
```

**Ch√∫ th√≠ch tham s·ªë:**

  * `--config`: (B·∫Øt bu·ªôc) Ch·ªâ ƒë·ªãnh file config YAML ch·ª©a m·ªçi c√†i ƒë·∫∑t (ƒë∆∞·ªùng d·∫´n data, learning rate, batch size...).
  * `--resume_from`: (T√πy ch·ªçn)
      * [cite_start]**ƒê·ªÉ hu·∫•n luy·ªán ti·∫øp (fine-tune):** D√πng tham s·ªë n√†y v√† tr·ªè ƒë·∫øn file `best_transformer.pt` ƒë√£ c√≥[cite: 9].
      * **ƒê·ªÉ hu·∫•n luy·ªán t·ª´ ƒë·∫ßu (from scratch):** **X√≥a** tham s·ªë n√†y ƒëi.

#### 2\. Hu·∫•n luy·ªán CRNN (Baseline)

Ch·∫°y training b·∫±ng c√°ch g·ªçi module `src.crnn.train`:

```cmd
python -m src.crnn.train --images_dir "data/images" --labels_json "data/labels.json" --output_dir "models/checkpoints_crnn_new" --device cuda --amp
```

**Ch√∫ th√≠ch tham s·ªë:**

  * `--images_dir`, `--labels_json`: ƒê∆∞·ªùng d·∫´n ƒë·∫øn d·ªØ li·ªáu hu·∫•n luy·ªán.
  * `--output_dir`: Th∆∞ m·ª•c ƒë·ªÉ l∆∞u checkpoint `best.pt` m·ªõi.
  * `--device cuda --amp`: TƒÉng t·ªëc training n·∫øu b·∫°n c√≥ GPU (khuy·∫øn kh√≠ch).

### C. ƒê√°nh gi√° (Evaluation)

(Gi·∫£ s·ª≠ b·∫°n ƒë√£ ƒë·∫∑t file test trong `data/test/images` v√† `data/test/labels.json`)

#### 1\. ƒê√°nh gi√° Transformer (TrOCR) + Language Model

Ch·∫°y ƒë√°nh gi√° b·∫±ng c√°ch g·ªçi module `src.transformer.eval_lm`:

```cmd
python -m src.transformer.eval_lm --checkpoint "models/best_transformer.pt" --test_images_dir "data/test/images" --test_labels_json "data/test/labels.json" --lm_path "models/3-gram-lm.binary" --output_file "evaluation_results.json" --beam_width 10 --lm_alpha 0.5 --lm_beta 0.2
```

**Ch√∫ th√≠ch tham s·ªë (R·∫•t quan tr·ªçng):**

  * `--checkpoint`: Tr·ªè ƒë·∫øn file model TrOCR (`.pt`) b·∫°n mu·ªën ƒë√°nh gi√°.
  * `--lm_path`: Tr·ªè ƒë·∫øn file model ng√¥n ng·ªØ (`.binary`).
  * `--output_file`: (T√πy ch·ªçn) L∆∞u k·∫øt qu·∫£ d·ª± ƒëo√°n chi ti·∫øt ra file JSON.
  * `--beam_width 10`: TƒÉng s·ªë "beam" cho k·∫øt qu·∫£ t·ªët h∆°n (nh∆∞ng ch·∫≠m h∆°n).
  * `--lm_alpha 0.5`, `--lm_beta 0.2`:
      * `lm_alpha`: S·ª©c m·∫°nh c·ªßa model ng√¥n ng·ªØ (cao h∆°n = ∆∞u ti√™n ng·ªØ ph√°p h∆°n).
      * `lm_beta`: Th∆∞·ªüng/ph·∫°t cho ƒë·ªô d√†i (word count).
      * [cite_start]**Ghi ch√∫:** Qua ki·ªÉm th·ª≠ (Task C3), b·ªô tham s·ªë `alpha=0.5` v√† `beta=0.2` cho k·∫øt qu·∫£ CER/WER c√¢n b·∫±ng v√† t·ªët nh·∫•t tr√™n t·∫≠p test[cite: 9].

#### 2\. ƒê√°nh gi√° CRNN (Baseline)

Ch·∫°y ƒë√°nh gi√° b·∫±ng c√°ch g·ªçi module `src.crnn.eval`:

```cmd
python -m src.crnn.eval --weights "models/best_crnn.pt" --images_dir "data/test/images" --labels_json "data/test/labels.json" --device cuda --amp --out_dir "outputs_eval_crnn"
```

**Ch√∫ th√≠ch tham s·ªë:**

  * `--weights`: Tr·ªè ƒë·∫øn file model CRNN (`.pt`) b·∫°n mu·ªën ƒë√°nh gi√°.
  * `--out_dir`: N∆°i l∆∞u file k·∫øt qu·∫£ `preds.csv` v√† `metrics.txt`.

### D. D·ª± ƒëo√°n 1 ·∫£nh (Predict)

#### 1\. D·ª± ƒëo√°n (Transformer + LM)

Ch·∫°y d·ª± ƒëo√°n 1 ·∫£nh b·∫±ng c√°ch g·ªçi module `src.transformer.predict_lm`:

```cmd
python -m src.transformer.predict_lm --checkpoint "models/best_transformer.pt" --image "data/test/images/t1.jpg" --lm_path "models/3-gram-lm.binary" --beam_width 10 --lm_alpha 0.5 --lm_beta 0.5
```

**Ch√∫ th√≠ch tham s·ªë:**

  * `--image`: ƒê∆∞·ªùng d·∫´n ƒë·∫øn ·∫£nh b·∫°n mu·ªën d·ª± ƒëo√°n.
  * `--lm_alpha 0.5`, `--lm_beta 0.5`: Tham s·ªë alpha/beta khi d·ª± ƒëo√°n 1 ·∫£nh c√≥ th·ªÉ c·∫ßn tinh ch·ªânh kh√°c v·ªõi khi ƒë√°nh gi√° h√†ng lo·∫°t (v√≠ d·ª•: `0.5`/`0.5`).

#### 2\. D·ª± ƒëo√°n (CRNN)

Ch·∫°y d·ª± ƒëo√°n 1 ·∫£nh b·∫±ng c√°ch g·ªçi module `src.crnn.predict`:

```cmd
python -m src.crnn.predict --weights "models/best_crnn.pt" --image "data/test/images/15520_samples.jpg" --device cuda --amp
```

### E. Ch·∫°y Web Demo (Local)

1.  **Ch·∫°y b·∫±ng Docker (Khuy·∫øn kh√≠ch):**

      * (ƒê·∫£m b·∫£o b·∫°n ƒë√£ `git lfs pull` ƒë·ªÉ c√≥ model trong `web_demo/models/`)

    ```bash
    cd web_demo
    docker build -t ocr-app .
    docker run -p 8000:8000 ocr-app
    ```

2.  **Ch·∫°y th·ªß c√¥ng (Local):**

      * C√†i ƒë·∫∑t c√°c th∆∞ vi·ªán ri√™ng c·ªßa web demo:
        ```bash
        pip install -r web_demo/requirements.txt
        ```
      * Ch·∫°y server FastAPI:
        ```bash
        # Ch·∫°y t·ª´ th∆∞ m·ª•c g·ªëc vn-handwriting-ocr/
        python -m uvicorn web_demo.app.main:app --host 0.0.0.0 --port 8000
        ```
      * M·ªü tr√¨nh duy·ªát t·∫°i: `http://localhost:8000`

-----

## Attribute

  * **Baseline CRNN:** [TomHuynhSG/Vietnamese-Handwriting-Recognition-OCR](https://github.com/TomHuynhSG/Vietnamese-Handwriting-Recognition-OCR)
  * **D·ªØ li·ªáu:** [nghiangh/UIT-HWDB-dataset](https://github.com/nghiangh/UIT-HWDB-dataset) v√† c√°c ngu·ªìn kh√°c.
